{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f000de1-495d-4a3b-b69d-5a0b6edc2842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from manyqa import ManyQA\n",
    "from huggingface_hub import login\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a524f04-b3d2-456e-8f35-59300a0f1372",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5e2590-734d-43c8-b559-98b328fa0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = os.getenv(\"HF_TOKEN\") or os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "assert hf_token, \"Ustaw zmienną środowiskową HF_TOKEN lub HUGGINGFACE_HUB_TOKEN z wartością hf_***\"\n",
    "login(token=hf_token, add_to_git_credential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6b81f-afb9-48c8-ab32-7ab85b460594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# załadowanie modelu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Uruchamiam na urządzeniu: {device}\")\n",
    "\n",
    "model_name = \"speakleash/Bielik-11B-v2.6-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    # load_in_8bit=True,\n",
    "    # load_in_4bit=True,\n",
    "    dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a2052-e17e-49df-8ec4-3d043b535366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(output: list[str]) -> str:\n",
    "    out = output[0].split('|im_start|>assistant\\n')[-1].replace('<|im_end|>', '')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73073cc2-0099-4943-98b1-00db918b2991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(messages: list[str], max_tokens: int = 500, temperature: float = 0.01, top_p: float = 0.01) -> str:\n",
    "    input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True)\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    \n",
    "    model_inputs = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        model_inputs, \n",
    "        attention_mask=attention_mask, \n",
    "        max_new_tokens=max_tokens, \n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "    return decode(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f3135b-5651-4e3e-a491-5b8972bbdf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test modelu\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Odpowiadaj krótko, precyzyjnie i wyłącznie w języku polskim.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Jakie mamy pory roku w Polsce?\"},\n",
    "    # {\"role\": \"assistant\", \"content\": \"W Polsce mamy 4 pory roku: wiosna, lato, jesień i zima.\"},\n",
    "    # {\"role\": \"user\", \"content\": \"Która jest najcieplejsza?\"}\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True)\n",
    "attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "model_inputs = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "model.to(device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs, \n",
    "    attention_mask=attention_mask, \n",
    "    max_new_tokens=500, \n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.1,\n",
    ")\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decode(decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d89df-5665-493a-a008-5fab56bd913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model odpowiedzi\n",
    "class Response(BaseModel):\n",
    "    # chain_of_thought: conlist(str, max_length=2) = Field(..., description=\"Łańcuch myśli\")\n",
    "    answer: str = Field(..., description='Odpowiedź na pytanie użytkownika')\n",
    "    confidence: float = Field(..., description='Liczba w skali od 0 do 1 oznaczająca pewność udzielenia poprawnej odpowiedzi. 1 oznacza całkowitą pewność poprawnej odpowiedzi')\n",
    "\n",
    "class AnswerCheck(BaseModel):\n",
    "    correct: bool = Field(False, description='Flaga oznaczająca czy udzielona odpowiedź jest poprawna z kluczem')\n",
    "    clarification: str = Field(..., description='Bardzo krótkie i rzeczowe wyjaśnienie decyzji')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c141858b-7a86-487a-a44c-76092d1b68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# załaduj obiekt z pytaniami\n",
    "with open('QAData.json', 'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "questions = ManyQA(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea89e7-9614-4f8a-b7b5-c7b3faf93b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test pytania\n",
    "question = questions.qa[0]\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67deeea9-6135-4c76-8745-869a65329a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zadanie pytania\n",
    "def ask_question(question) -> str:\n",
    "    sys_instr = (\n",
    "            \"Jesteś ekspertem od historii polski\\n\"\n",
    "            \"Zwróć WYŁĄCZNIE poprawny JSON, bez komentarzy, bez ``` i bez dodatkowego tekstu. \"\n",
    "            \"JSON musi być zgodny ze schematem: \" + json.dumps(Response.model_json_schema(), ensure_ascii=False) +\n",
    "            '\\nPrzykład: {\"answer\": \"63\", \"confidence\": 0.83}' \n",
    "        )\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': sys_instr},\n",
    "        {'role': 'user', 'content': f\"Pytanie: {question.question}\\nOczekiwany format odpowiedzi: {question.answer_format}\"}\n",
    "    ]\n",
    "    \n",
    "    response = generate(messages)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17708bbe-92f3-433d-bbff-f8374fdf1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdzenie poprawności odpowiedzi\n",
    "def check_asnwer(question, model_resp) -> str:\n",
    "    example = '{\"correct\": true, \"clarification\": \"Odpowiedź jest poprawna, ponieważ dokładnie odpowiada kluczowi.\"}'\n",
    "    ex1 = '{\"correct\": true, \"clarification\": \"Odpowiedź jest poprawna — użytkownik wskazał właściwą osobę.\"}'\n",
    "    ex2 = '{\"correct\": false, \"clarification\": \"Niepoprawna — użytkownik podał nazwę wydarzenia zamiast osoby.\"}'\n",
    "    ex3 = '{\"correct\": false, \"clarification\": \"Niepoprawna — użytkownik podał nazwę warzyw zamiast osoby (królowej Bony).}'\n",
    "    ex4 = '{\"correct\": false, \"clarification\": \"Niepoprawna — użytkownik podał nazwę organizacji emigracyjnej (Towarzystwo Demokratyczne Polski), a nie grupy młodych artystów (Cyganeria Warszawska).}'\n",
    "    ex5 = '{\"correct\": false, \"clarification\": \"Niepoprawna — użytkownik nie podał wszystkich funkcji jakie pełnił Jan Zamoyski.}'\n",
    "    sys_instr = f\"\"\"ROLA: Jesteś egzaminatorem testów.\n",
    "    \n",
    "ZADANIE: Twoim zadaniem jest określenie, czy odpowiedź użytkownika jest **merytorycznie zgodna** z podanym kluczem (poprawną odpowiedzią).\n",
    "\n",
    "ZASADY OCENY:\n",
    "1. Odpowiedź musi znaczeniowo odpowiadać kluczowi — czyli wskazywać to samo zjawisko, osobę, miejsce, wydarzenie lub pojęcie.\n",
    "2. Dopuszczalne są drobne różnice językowe (np. 'powstania listopadowego' vs 'Powstanie Listopadowe').\n",
    "3. Jeśli użytkownik odpowiada nie na temat lub podaje tylko coś związanego, ale nie tożsamego z kluczem — odpowiedź jest **niepoprawna**.\n",
    "4. Wyjaśnienie (clarification) ma być krótkie, jednozdaniowe i rzeczowe.\n",
    "5. Dopuszczalne są odpowiedzi w innych częściach mowy. Odpowiedź: 'powstania listopadowego' jest poprawna dla klucza: 'Powstanie Litopadowe'\n",
    "\n",
    "WYJŚCIE: Zwróć WYŁĄCZNIE poprawny JSON, bez komentarzy, bez ``` i bez dodatkowego tekstu.\n",
    "JSON musi być zgodny ze schematem: {json.dumps(AnswerCheck.model_json_schema(), ensure_ascii=False)}\n",
    "\n",
    "PRZYKŁADY:\n",
    "\n",
    "PYTANIE: Kto był przywódcą powstania listopadowego?\n",
    "KLUCZ: Piotr Wysocki\n",
    "ODPOWIEDŹ: Piotr Wysocki\n",
    "OCENA: {ex1}\n",
    "\n",
    "PYTANIE: Kto był przywódcą powstania listopadowego?\n",
    "KLUCZ: Piotr Wysocki\n",
    "ODPOWIEDŹ: powstanie listopadowe\n",
    "OCENA: {ex2}\n",
    "\n",
    "PYTANIE: Dzięki komu na polskie stoły trafiły nieznane wcześniej warzywa zwane włoszczyzną?\n",
    "KLUCZ: Królowej Bonie\n",
    "ODPOWIEDŹ: włoszczyzna\n",
    "OCENA: {ex3}\n",
    "\n",
    "PYTANIE: Ośmieszali stroje salonowe i konwencje obyczajowe. Ich nieoficjalnym, własnym pismem była gazeta \"Nadwiślanin\". Głosili idee demokratyczno-ludowe. Mowa o przedstawicielach…\n",
    "KLUCZ: Cyganerii warszawskiej\n",
    "ODPOWIEDŹ: Towarzystwa Demokratycznego Polskiego\n",
    "OCENA: {ex4}\n",
    "\n",
    "PYTANIE: Jaką funkcję pełnił Jan Zamoyski w Rzeczypospolitej: Hetman wielki koronny, Kanclerz wielki koronny czy Generalny starosta krakowski? \n",
    "KLUCZ: Wszystkie wymienione\n",
    "ODPOWIEDŹ: Hetman wielki koronny, Kanclerz wielki koronny\n",
    "OCENA: {ex5}\n",
    "\n",
    "PYTANIE: {question.question}\n",
    "KLUCZ: {question.answer}\n",
    "\"\"\"\n",
    "    \n",
    "    t = model_resp.split('\"answer\": ')[-1].split(', \"')[0]\n",
    "    \n",
    "    user_instr = f\"\"\"ODPOWIEDŹ: {t}\"\"\"\n",
    "    messages = [\n",
    "            {'role': 'system', 'content': sys_instr},\n",
    "            {'role': 'user', 'content': user_instr}\n",
    "    ]\n",
    "    return generate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1883e7cf-db1d-40b3-b523-8ac8dc61463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#przygotowanie liczników\n",
    "correct_q, all_q = 0, 0\n",
    "difficult_questions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f17de44-e4a3-4b5d-a09e-948ef2b5c8c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# uruchomienie testu\n",
    "import time\n",
    "from datetime import datetime\n",
    "for question in questions.qa:\n",
    "    all_q += 1\n",
    "    print('\\n'+ str(datetime.now()))\n",
    "    print(f\"Pytanie: {question.question}\")\n",
    "    start = time.perf_counter()\n",
    "    model_response = ask_question(question)\n",
    "    time_to_answer = time.perf_counter() - start\n",
    "    print(model_response)\n",
    "    print(f\"({question.answer}) Sprawdzanie odpowiedzi...\")\n",
    "    correctness = check_asnwer(question, model_response)\n",
    "    print(correctness)\n",
    "    if '\"correct\": true' in correctness:\n",
    "        correct_q+=1\n",
    "    else:\n",
    "        difficult_questions.append(question)\n",
    "    tup = {\n",
    "        'datetime': str(datetime.now()),\n",
    "        'question': question.question,\n",
    "        'model_response': model_response,\n",
    "        'correctness': correctness,\n",
    "        'time_to_answer': time_to_answer\n",
    "    }\n",
    "    with open('0experiment_bielik.jsonl', 'a') as f:\n",
    "        f.write(json.dumps(tup, ensure_ascii=False))\n",
    "        f.write('\\n')\n",
    "    print(f\"Aktualny wynik: {correct_q}/{all_q} odpowiedzi poprawnych.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9d970-3944-4150-b83e-67c94e71496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wynik pierwszej iteracji to XXX/570, czyli XX%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028ba0e-b006-41b9-b9f4-05ca0aafef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in difficult_questions:\n",
    "    print(q.question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
